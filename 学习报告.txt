作为编程新手，我在过去五天内从零开始系统性学习机器学习基础，目标是通过实践掌握经典算法原理、数据预处理方法及工程化工具，最终完成从理论到代码落地的全流程验证。


1. Python基础与文件操作  
学习内容：掌握`open()`读写文件、路径管理、CSV/JSONL格式解析。  
实践成果：通过爬虫脚本生成jsonl数据文件，并实现数据清洗与标准化。  
难点突破：JSONL格式的逐行解析与异常处理，通过编写循环逻辑与`try-except`解决格式错误问题。

2. 决策树与随机森林  
学习路径：  
Scikit-learn快速实现：基于鸢尾花数据集调用`DecisionTreeClassifier`，理解特征选择与模型评估（准确率、混淆矩阵）。  
手动实现决策树：使用`numpy`从零编写ID3算法，核心为信息增益计算与递归分裂逻辑。  
随机森林扩展：通过Bootstrap采样与特征子集选择提升模型稳定性，手动实现多棵决策树集成。  
成果验证：在鸢尾花数据集上手动模型与Scikit-learn结果一致（准确率>95%）。

3.  
Pandas数据清洗：处理缺失值（`dropna`）、去重（`drop_duplicates`）、文本正则化（`re.sub`）。  
Git版本控制。  

4. 深度学习初探  
BERT微调实战：基于PyTorch实现中文评论评分预测，掌握Tokenizer编码、Dataset封装与训练循环。  
难点：  
  - Hugging Face模型下载因网络问题卡顿，通过镜像站（`hf-mirror.com`）解决。  
  - GPU显存不足导致OOM，调整`batch_size`与梯度累积优化。  

核心困难 
数学推导与代码实现
问题：手动实现决策树时，信息增益计算与递归终止条件逻辑混乱。  
 
数据清洗中的逻辑漏洞 
  问题：正则表达式处理文本时误删有效信息（如中文标点）。  
  解决：设计多组测试用例（含特殊符号、HTML标签），逐步调整正则模式

核心收获 
技术层面：掌握机器学习基础算法（决策树、随机森林）与深度学习微调流程，熟悉Python数据科学生态（Pandas、NumPy、Hugging Face）。  
方法：形成“理论-代码-调试-优化”的闭环学习模式，强化问题拆解与Debug能力。  

2. 待提升方向  
数学基础：概率论与矩阵运算需系统补强，以理解更复杂模型（如SVM、神经网络）。  
工程能力：引入MLflow或W&B实现实验跟踪，提升代码可复现性。  


总结：五天的高强度学习让我深刻体会到“从做中学”的高效性。会继续努力。